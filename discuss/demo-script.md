# 职遇（TalentDrop）5 分钟 Demo 脚本

> **赛道**：与智能体共生与智能市场
> **扣题角度**：高度个性化、长生命周期的招聘智能体 + 面向匹配场景的上下文获取/管理/更新方案 + 具备强执行能力的工作流 + 数据采集/反馈/激励闭环
> **核心叙事线**：Date Drop 验证模式 → 招聘智能体不只是聊天 → LightRAG 赋予长期上下文 → 反馈闭环让智能体持续进化
> **提前打开**：Tab1: `localhost:3000`（首页） / Tab2: `localhost:3000/demo`

---

## 第一幕：Hook + 为什么是智能体（1 分钟）

> **操作**：Tab2 `/demo`，滚动到「Date Drop 对标」分区

### 讲解

先讲一个故事。

有个约会 App 叫 **Date Drop**，斯坦福孵化。
它砍掉了左滑右滑，换成 50 道深度心理学问卷，每周只给你推 1 个人。
结果——配对成功率是 Tinder 的 **10 倍**。

> **操作**：指向 Date Drop 四宫格数据

为什么？因为它做了一件简单但反直觉的事：**先花时间理解你是谁，再给你推人**。

招聘是完全相同的问题——97% 简历石沉大海，46% 新人 90 天内文化错配离职。
海投简历就是招聘版的"左滑右滑"——效率低、质量差。

但招聘比约会**复杂得多**。
约会理解两个人就够了；招聘要理解候选人、公司文化、团队风格、岗位需求……
这些信息散落在简历、对话、问卷里，格式各异、持续变化。

**这不是一个对话问题——这是一个智能体问题。**

我们需要一个智能体做三件事：
1. **持续收集和记住上下文**——不是聊一次就忘
2. **执行完整工作流**——不是只能聊天，要能打分、匹配、生成报告
3. **用起来越来越准**——每一次匹配结果都让下一次更好

这就是**职遇**——一个用 LightRAG 知识图谱作为长期记忆的招聘匹配智能体。

---

## 第二幕：智能体怎么理解人（1 分钟）

> **操作**：滚动到「Career DNA」分区，停 2 秒，再滚到「匹配引擎」

### 讲解

智能体理解一个人，靠三个渠道：

**第一个：Career DNA 问卷**——基于心理学 Big Five 模型，提炼出 8 个职业维度。
比如你喜欢快节奏还是深度打磨？独立工作还是团队协作？数据驱动还是直觉驱动？
30 道题，没有正确答案，关键是**匹配**。

**第二个：AI 对话**——候选人跟智能体自然聊天，
智能体从对话中提取关键信息：你擅长什么技术、想要什么环境、在意什么。

**第三个：简历解析**——上传 PDF，AI 自动提取技能、经验、教育背景。

> **操作**：指向引擎层级

这三个渠道产生两类数据——**结构化的**（问卷打分）和**非结构化的**（聊天内容、简历文本）。

结构化数据好处理，直接算向量距离。
但非结构化数据才是最有价值的——候选人说"我想找不卷的团队"，
这句话蕴含的信息，光靠打分捕捉不到。

**LightRAG 做的事情就是：把这些散落的文本信息，变成知识图谱里的节点和关系。**

举个例子：候选人聊天说"我想找不卷的团队"——
普通做法：这句话存在聊天记录里，下次调用 LLM 时可能已经不在上下文窗口里了。
LightRAG：提取出"这个人重视工作生活平衡"，写进图谱，**永久保留**。
以后做匹配、生成报告、推荐岗位时，这个信息都在。

**简单说：LightRAG 让智能体有了长期记忆，不会聊完就忘。**

---

## 第三幕：不只是聊天——看工作流（1 分 30 秒）

> **操作**：切到 Tab1，点击「Alex Chen」登录

接下来看智能体实际怎么工作——不是对话，是完整的工作流。

> **操作**：自动进入 `/candidate/dashboard`，停 3 秒

### 3.1 画像构建

这是 Alex 的 **Career DNA 画像**——智能体整合三个渠道的数据，生成 8 维雷达图。
一眼看出 Alex 的特点：快节奏、偏独立、数据驱动。

注意上面的**一致性评分**——如果候选人答题前后矛盾（比如前面说喜欢独立，后面又选团队协作），
系统会自动标记。这不是被动收数据，是**智能体在主动做数据质量控制**。

> **操作**：点击左侧「每周推荐」

### 3.2 匹配和推送

每周二晚 9 点，智能体自动跑匹配：
先做**硬性过滤**——技能不匹配、地点不对的直接排除；
再算 **DNA 兼容性**——8 个维度的距离，乘以一致性系数。

然后精选 1-3 个推给候选人——不是推 100 个让你挑，而是**少而精**。
这是 Date Drop 验证过的：稀缺推荐让人更认真对待每一个匹配。

Velocity Labs 匹配度最高，91%。

> **操作**：点击 Velocity Labs「查看报告」

### 3.3 匹配报告 + 知识图谱

匹配报告不是模板拼的——智能体结合匹配分数和上下文，用 LLM 生成可读的分析。
它告诉你**为什么匹配度高**："Alex 偏好快速迭代，Velocity Labs 是敏捷文化。"

> **操作**：切到「知识图谱」Tab，停 3 秒

**这就是智能体的记忆可视化**——LightRAG 构建的关系网络。
蓝色是候选人，紫色是公司，黄色是技能，粉色是 DNA 维度。
你能直观看到 Alex 和 Velocity Labs 通过哪些节点连在一起。

这个图谱是**活的**——每多一个候选人、每多一次对话，图谱就更丰富一点。

> **操作**：回到报告，点击「接受匹配」

Alex 接受了——但只是单方面的，企业也要接受才行。

---

## 第四幕：双向市场 + 互匹配（1 分钟）

> **操作**：退出，回首页，点击「Velocity Labs」登录

现在切到企业视角。

> **操作**：进入 `/company/dashboard`，快速扫

企业也有自己的 DNA 画像。这里多一个指标——**CAS 文化真实度评分**。

这个分数的逻辑是：如果公司里多个人填了企业 DNA 问卷，
系统会比较大家答案的一致程度。
如果 HR 说"我们不加班"，但员工的答案暗示高强度，一致性就会低。
**简单说：防止企业画大饼。**

> **操作**：点击「每周推荐」，找到 Alex Chen

企业推荐按岗位分组。Alex 状态"待处理"——候选人接受了，企业还没操作。

> **操作**：点击「接受」

**绿色横幅——「双向匹配成功」！**

候选人接受，企业也接受，互匹配触发。
**智能体在两端同时工作——它是这个双向市场的撮合者。**

---

## 第五幕：为什么会越用越准（30 秒）

> **操作**：切回 Tab2，滚动到「数据飞轮」分区

### 讲解

最后说说这个智能体为什么能**长生命周期、持续进化**。

我用一个具体例子讲完整个闭环——

Alex 入职 Velocity Labs 了。3 个月后我们追踪：他干得开心吗？留下来了吗？
答案是留下来了，而且满意度很高。

**这条结果数据怎么反馈到匹配机制上？两步。**

**第一步：写入图谱。**
系统在知识图谱里新增一条关系：
`Alex(快节奏/独立型) → [留存成功] → Velocity Labs(敏捷文化)`。
这不是存进数据库的一行记录——它是图谱里一条**有上下文的边**，
连着 Alex 的 8 维 DNA、Velocity Labs 的文化特征、岗位要求。

**第二步：影响下一次匹配。**
下次来了一个新候选人 Bob，也是快节奏、独立型。
系统做匹配的时候，LightRAG 会被查询：
"和 Bob 特质相似的人，在什么样的公司表现好？"
图谱里有 Alex 的成功案例——系统对 Velocity Labs 这类公司的匹配**打分更高**。

反过来，如果 Alex 3 个月就走了，图谱记录的是失败。
下次类似的人配上类似的公司，分数就会**被压低**。

**这就是图谱影响匹配的完整路径：结果 → 图谱 → 检索 → 影响打分。**

积累 100 个人的结果后，系统开始发现规律——
比如"工作节奏"可能比"决策风格"更影响留存，权重自动调整。
1000 个人之后，系统比任何 HR 都清楚"什么样的人适合什么样的公司"。

**普通 LLM 每次调用都是从零开始——它不记得上一个人的结果。
LightRAG 的图谱持续积累——每一个匹配结果都让下一次更准。**

这就是职遇——一个有长期记忆、能自动执行、会越用越聪明的招聘智能体。
**让每一次职业选择，都是双向奔赴。**

谢谢。

---

## 附录

### 扣题对照表

| 赛道要求 | 职遇的回答 | 演示体现 |
|---------|----------|---------|
| 智能体如何获得长期有效上下文？ | LightRAG 知识图谱 = 长期记忆，三渠道数据持续写入 | 知识图谱 Tab |
| 如何设计工作流而非仅是对话？ | 画像构建 → 多层匹配 → 报告生成 → 双向推送，全自动 | 每周推荐 + 匹配报告 |
| 数据/感知/执行/激励如何协同？ | 入职追踪 → 结果写回图谱 → 权重自动调整 → 匹配更准 | 数据飞轮分区 |
| 高度个性化、长生命周期智能体 | Career DNA 画像 + 图谱越来越丰富 = 越来越懂你 | DNA 雷达图 |
| 面向特定场景的上下文管理方案 | 招聘场景三渠道采集 + LightRAG 增量管理 + 结果反馈 | 全流程 |

### 防 Challenge 话术

| 可能的挑战 | 应对 |
|-----------|------|
| "LightRAG 和直接调 OpenAI 有什么区别？" | "OpenAI 每次调用不记得上一次的结果。LightRAG 的图谱会持续积累——第 100 个人的入职反馈，会让第 101 个人的匹配更准。" |
| "你说的进化，现在做到了吗？" | "现在 Demo 阶段，图谱的结构和写入通道已经搭好了。进化需要真实数据——第一批用户跑起来，3 个月后入职反馈回来，写进图谱，下一轮匹配查询图谱时就能用到。架构已经是这个链路了。" |
| "图谱怎么影响匹配分数？" | "匹配的时候，系统会查询图谱：'跟这个候选人相似的人，在什么公司干得好？' 有成功案例的组合打分更高，有失败案例的打分更低。不是玄学，就是历史数据在起作用。" |
| "知识图谱和传统数据库有什么区别？" | "数据库存的是一条条独立记录。知识图谱存的是关系——A 擅长 React、React 属于前端、这个岗位需要前端。有了关系，智能体才能做推理，而不只是查询。" |
| "为什么不直接把所有数据丢给大模型？" | "上下文窗口有限，1000 个候选人的资料塞不进去。而且每次都要重新处理，成本很高。知识图谱做的是预处理和持久化——需要的时候检索相关部分就行。" |
| "一致性评分怎么算的？" | "同一个维度我们会从不同角度出多道题，比较答案是否一致。前后矛盾越多，一致性越低。" |

### 演示前检查

- [ ] `bash scripts/dev-backend.sh` → `bash scripts/seed-db.sh` → `bash scripts/dev-frontend.sh`
- [ ] Tab1: `localhost:3000`，Tab2: `localhost:3000/demo`（定位到 Date Drop 对标）
- [ ] Alex Chen 登录验证：DNA 数据 + 每周推荐有结果
- [ ] Velocity Labs 登录验证：企业推荐有候选人
- [ ] **确保 Alex 未接受任何匹配**（否则重新 seed）
- [ ] 全屏 + 字体放大两档

### 路线速记

```
/demo#compare（Date Drop 故事 → 为什么是智能体，1 分钟）
  ↓ 滚动
/demo#dna → /demo#engine（三渠道 + LightRAG 长期记忆，1 分钟）
  ↓
/ → Alex Chen 登录
  ↓
/candidate/dashboard（DNA 画像 + 一致性）
  ↓
/candidate/drop → Velocity Labs 报告
  ↓
/candidate/match/{id}（报告 + 知识图谱 → 接受）
  ↓ 退出
/ → Velocity Labs 登录
  ↓
/company/dashboard（CAS 一扫）
  ↓
/company/drop（接受 Alex → 互匹配 🎉）
  ↓
/demo#flywheel（为什么越用越准，30 秒收尾）
```

### 关键话术备忘

| 时刻 | 话术 |
|------|------|
| Hook | "Date Drop 砍掉左滑右滑，成功率 10 倍。招聘不也是同一个问题吗？" |
| 扣题转折 | "这不是对话问题——这是一个智能体问题" |
| LightRAG 定位 | "LightRAG 让智能体有了长期记忆，不会聊完就忘" |
| 工作流强调 | "这不只是聊天，是画像→匹配→报告→推送的完整工作流" |
| CAS | "简单说：防止企业画大饼" |
| 互匹配 | （放慢）"智能体在两端同时工作——它是双向市场的撮合者" |
| 进化逻辑 | "结果写进图谱，下次匹配时查询图谱，成功案例加分、失败案例减分——就是这么直接" |
| 收尾金句 | "普通 LLM 每次从零开始，LightRAG 图谱持续积累——每个结果让下一次更准" |
